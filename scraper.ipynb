{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "import urllib.request as web\n",
    "import newspaper as np           # /!\\ care with numpy alias\n",
    "import feedparser as fp\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from time import perf_counter \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 14.3M  100 14.3M    0     0   926k      0  0:00:15  0:00:15 --:--:--  965k0:00:08  0:00:08  986k5  0:00:13  0:00:02 1033k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   916  100   916    0     0   2726      0 --:--:-- --:--:-- --:--:--  2726\n"
     ]
    }
   ],
   "source": [
    "! curl -O https://people.irisa.fr/Guillaume.Gravier/teaching/ENSAI/data/lemonde.json \n",
    "! curl -O https://people.irisa.fr/Guillaume.Gravier/teaching/ENSAI/data/sources.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/abdoulayediallo/Documents/ENSAI/Cours/NLP/projets/web-scraping-lemonde'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marchés, Indices, matières premières, analyses de séance, Taux\n",
      " \n",
      "Wed, 10 Feb 2021 18:24:00 +0200\n",
      " \n",
      "Paris Clôture : Les stocks de pétrole aux Etats-Unis sont venus chambouler la Bourse en toute fin de séance Wed, 10 Feb 2021T17:41:00 +0200 https://investir.lesechos.fr/marches/actualites/les-stocks-de-petrole-aux-etats-unis-sont-venus-chambouler-la-bourse-de-paris-en-toute-fin-de-seance-1948748.php?xtor=RSS-24\n"
     ]
    }
   ],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# (b) recuperer le fichier RSS\n",
    "url = \"https://investir.lesechos.fr/RSS\"\n",
    "fn = \"info-marches-investir-bourse-les-echos.xml\"\n",
    "data = fp.parse(\"/\".join([url,fn]))\n",
    "\n",
    "# (c) visualiser les elements du fichier RSS\n",
    "print(data.feed.title)\n",
    "print(\" \")\n",
    "print(data.feed.published)\n",
    "print(\" \")\n",
    "# (d) iterer sur les entrees du flux RSS\n",
    "for item in data.entries:\n",
    "    print(item.title, item.published, item.link)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÉCOUTE RSS ET EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "### Data load: lemonde\n",
    "    - Lecture de la base de données existantes lemonde.json\n",
    "    – regardez au passage la structure de ce fichier json et les informations qu’il contient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3041 entries of lemonde\n"
     ]
    }
   ],
   "source": [
    "with open(\"data_in/lemonde.json\", 'r') as l:\n",
    "    lemonde = json.load(l)\n",
    "\n",
    "print('Loaded', len(lemonde), \"entries of lemonde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " ('https://www.lemonde.fr/international/article/2020/12/06/l-ue-met-en-place-un-nouveau-regime-de-sanctions-transversales_6062390_3210.html',\n",
       "  {'title': 'L’UE met en place un nouveau régime de sanctions transversales',\n",
       "   'date': '2020-12-06T14:00:08',\n",
       "   'author': ['Laurence Girard',\n",
       "    'Taha Oudghiri',\n",
       "    'Vice-Président De L Association Marocaine Des Économistes D Entreprises Ameen',\n",
       "    'Stéphane Foucart',\n",
       "    'Jean-Pierre Stroobants',\n",
       "    'Bruxelles',\n",
       "    'Bureau Européen'],\n",
       "   'category': 'Europe',\n",
       "   'content': 'L’opposant russe Alexeï Navalny, le 22 août 2019 à Moscou. Alexander Zemlianichenko / AP\\n\\nLe « nouveau régime de sanctions transversales » que les ministres des affaires étrangères de l’Union européenne devraient approuver lundi 7 décembre, à Bruxelles, va peut-être clore des années de discussion et ramener l’Union à son exact niveau d’ambition. Qui ne peut plus être vraiment celui du « pouvoir transformateur » dont rêvaient certains, mais celui d’un acteur de rang intermédiaire, encore capable de rappeler ses valeurs.\\n\\nLe texte ne portera pas le nom de « Magnitski », pour ne pas heurter la sensibilité prorusse de certains pays membres et pour ne pas pointer dans la seule direction de Moscou en évoquant le nom de Sergueï Magnitski, ce juriste russe mort en détention en 2009, torturé parce qu’il avait dénoncé une vaste affaire de corruption.\\n\\nEt il requerra, toujours, l’unanimité des Vingt-Sept. Officiellement pour lui conférer plus de force ; en réalité pour ne pas accroître les tensions et les divisions lorsqu’il s’agira de sanctionner les auteurs des atteintes aux droits de l’homme dans telle ou telle partie du monde.\\n\\nLire aussi La CEDH condamne lourdement la Russie dans l’affaire Magnitski\\n\\nCe ne sera donc pas entièrement un « Global Magnitsky Act », comme celui dont se sont dotés les Etats-Unis en 2016, imités ensuite par le Canada, le Royaume-Uni et les trois Etats baltes (l’Estonie, la Lettonie et la Lituanie). A savoir, des lois élargies à tous les suspects de violation des droits de l’homme – pas seulement russes – mais aussi d’actes majeurs de corruption dans le monde. En effet, même si le Parlement européen, dans une résolution votée en mars 2019, visait clairement les activités de « corruption systématique », les textes du Conseil ne retiennent apparemment pas ce point. « Faute d’une définition précise en droit international, et parce que la corruption peut être attaquée par d’autres mécanismes », indique une source.\\n\\nImpulsion décisive\\n\\nLe projet vise à punir, avec les armes traditionnelles de l’Union – pour l’essentiel, gel des avoirs, interdiction de visas et de voyages – les auteurs d’atteintes graves aux droits de l’homme. De manière « flexible » sans que leur pays soit visé. Et la liste des violations retenues est longue : crime contre l’humanité, génocide, torture, arrestations arbitraires, trafic d’êtres humains, violences sexuelles, entrave au droit de rassemblement, etc.\\n\\nInitié par les Pays-Bas en 2018, soutenu par la présidente de la Commission européenne et le haut représentant Josep Borrell, le projet a connu une impulsion décisive à la suite de la tentative d’empoisonnement de l’opposant russe Alexeï Navalny, victime d’un agent neurotoxique du groupe Novitchok en août et évacué vers l’Allemagne, où il a été soigné.\\n\\nIl vous reste 33.52% de cet article à lire. La suite est réservée aux abonnés.',\n",
       "   'image_link': 'https://img.lemde.fr/2020/11/30/241/0/4657/2326/1440/720/60/0/865142e_ef3ccc0203b4492eb3ac02ecb0450133-ef3ccc0203b4492eb3ac02ecb0450133-0.jpg',\n",
       "   'image_file': './lm-db/images/865142e_ef3ccc0203b4492eb3ac02ecb0450133-ef3ccc0203b4492eb3ac02ecb0450133-0.jpg'}))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v) for k, v in enumerate(lemonde.items())][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifier les informations disponibles dans le flux RSS de l’exemple ci-dessus et les éléments correspondants dans la structure de données retournées par fp.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kys = []\n",
    "df = {}\n",
    "for keys, values in lemonde.items():\n",
    "    for k, v in values.items():\n",
    "        kys.append(k)\n",
    "        df[k] = v\n",
    "        \n",
    "# Sanity check\n",
    "len(kys) == len(lemonde.items())*len(set(kys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author', 'category', 'content', 'date', 'image_file', 'image_link', 'title'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Les attributs disponible dans la base\n",
    "set(kys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pour chacun des flux RSS listés dans le fichier sources.json :\n",
    "\n",
    "    – Lire les données du flux RSS\n",
    "    – Scanner les articles et repérer ceux qui ne sont pas deja présent dans la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14 entries of source\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "with open(\"data_in/sources.json\", 'r') as s:\n",
    "    source = json.load(s)\n",
    "print('Loaded', len(source), \"entries of source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a  273 liens manquant. Sans doublons il y'a  229 \n",
      "\n",
      "['https://www.lemonde.fr/m-le-mag/article/2021/02/05/le-proces-des-colston-4-ravive-les-tourments-de-bristol-sur-son-passe-negrier_6068939_4500055.html', 'https://www.lemonde.fr/economie/article/2021/02/08/veolia-lance-les-hostilites-contre-suez-qui-se-rebiffe_6069168_3234.html', 'https://www.lemonde.fr/afrique/article/2021/02/10/negocier-avec-les-djihadistes-au-burkina-faso-une-option-de-moins-en-moins-taboue_6069462_3212.html', 'https://www.lemonde.fr/afrique/article/2021/02/10/ethiopie-80-du-tigre-est-inaccessible-pour-l-aide-humanitaire-selon-la-croix-rouge-locale_6069488_3212.html', 'https://www.lemonde.fr/emploi/article/2021/02/10/les-entreprises-confrontees-au-defi-de-la-remotivation-des-salaries_6069414_1698637.html']\n",
      "....................\n"
     ]
    }
   ],
   "source": [
    "# new df\n",
    "liens_manquants = []\n",
    "for categories, links in source.items():\n",
    "    parsedlinks = fp.parse(links)\n",
    "    category = categories\n",
    "        # update de la base existante\n",
    "    for entry in parsedlinks.entries:\n",
    "        link = entry.link\n",
    "        if link not in lemonde.keys():\n",
    "            liens_manquants.append(link)\n",
    "            \n",
    "# head des liens non existant dans la base de données\n",
    "\n",
    "print(\"Il y a \",len(liens_manquants), \"liens manquant.\", \"Sans doublons il y'a \", len(set(liens_manquants)), \"\\n\")\n",
    "\n",
    "liens_manquants = list(set(liens_manquants)) # On dédoublonne\n",
    "print(liens_manquants[:5]) # Affichage des 5 premiers  items seulement\n",
    "print(\"..\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: \n",
    "\n",
    "## 2\n",
    "    - Pour l’un des articles de votre flux RSS, regardez le code HTML de la page web. Pouvez-vous identifier les zones contenant le titre de l’article ? le texte de l’article ? En quoi le recours à la librairie newspaper3k est-il utile ? Quelles informations peut-on ainsi récupérer concernant un article ?TODO: \n",
    "\n",
    "\n",
    "**Réponse:**  \n",
    "- Identification des zones contenant le titre de l’article\n",
    "    - Le title est. dans `class=\"article__heading\"`  \n",
    "    - le text est dans `class=\"article__wrapper \"`\n",
    "\n",
    "- **Newspaper3k** permet de reconnaitre automatiquement les balise dans un documents html et de facilité le parsing des données et leur scraping.\n",
    "\n",
    "- On peut récupere le caption des images dans `class=\"article__legend\"`et le temps de lecture ncessaire dans `class=\"meta__reading-time meta__reading-time--header\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "Reprendre votre programme de scrapping et le compléter de maniere à mettre a jour votre base de données avec le texte des articles du flux RSS et le lien vers l’image illustrant l’article lorsqu’il y en a une.  \n",
    "Vous pouvez inclure d’autres informations qui vous semblent utile pour un traitement ultérieur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before updating data:  3041\n",
      "Length after updating data:  3271\n",
      "Temps:  1037.3 s\n"
     ]
    }
   ],
   "source": [
    "liens_existant = lemonde.keys() \n",
    "update_monde = lemonde.copy() # to not lose raw data\n",
    "\n",
    "t1 = perf_counter()  \n",
    "print(\"Length before updating data: \", len(update_monde))\n",
    "# new df\n",
    "for url in source.values():\n",
    "    new_df = fp.parse(url)\n",
    "    category = url[re.search(r'.fr/', url).start()+4:].split(\"/\")[0] # retrieve new categories \n",
    "    \n",
    "    # update de la base existante\n",
    "    for item in new_df.entries:\n",
    "        link = item.link\n",
    "        time.sleep(3)\n",
    "        if link not in liens_existant:\n",
    "            article = np.Article(link)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            update_monde[link] = {'title' : article.title,\n",
    "                             'date' : article.publish_date.isoformat(), \n",
    "                             'author' : article.authors, \n",
    "                             'category' : category, \n",
    "                             'content' : article.text, \n",
    "                             'image_link' : article.top_image}\n",
    "    t2 = perf_counter()\n",
    "\n",
    "print(\"Length after updating data: \", len(update_monde))\n",
    "print(\"Temps: \",round((t2-t1),1), \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_out/update_lemonde\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".json\", 'w') as update_:\n",
    "    json.dump(update_monde, update_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap in function\n",
    "Vous reformulerez le code de votre programme de scrapping de manière à en faire une fonction prenant en entrée la base de données dans son état actuel et la liste des flux à écouter et retournant la base de donéees mise à jour.    \n",
    "   **En pratique**, comment utiliseriez-vous cette fonction (pensez à la sauvegarde des données, à la nécessité d’une mise à jour à intervalle régulier, etc.) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updatrss(sourceslinks, df_to_update, sleeptime=0):\n",
    "    \"\"\" \n",
    "    Input:\n",
    "    ------\n",
    "    sourceslinks: link to parse/scan for updating df_to_update: dict variables where keys are links (in our case)\n",
    "                  change it to list using *sourceslinks if you've a list of link.\n",
    "    df_to_update: json file containing to update\n",
    "    sleeptime: (optional) time to wait for next data retrieval from website.\n",
    "               lemonde.fr/robots.txt) ne précise pas de sleeptime, il faut tester plusieurs sleeptime si vous avez 403.\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    df_to_update: json file updated\n",
    "    failledlink: failled link to download\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Length before updating data: \", len(df_to_update))\n",
    "    time.sleep(sleeptime) # to be edited at your convenience, deaful est à 0, some bots may denied your multiplied request.\n",
    "\n",
    "    failledlink = []\n",
    "    for url in sourceslinks.values():\n",
    "        new_df = fp.parse(url)\n",
    "        category = url[re.search(r'.fr/', url).start()+4:].split(\"/\")[0] # retrieve new categories \n",
    "\n",
    "        # update de la base existante\n",
    "        for item in new_df.entries:\n",
    "            link = item.link\n",
    "            time.sleep(sleeptime)\n",
    "            liens_existant = df_to_update.keys() # Lien issue et existant dans notre base disponible, lemonde.\n",
    "            if link not in liens_existant:\n",
    "                article = np.Article(link)\n",
    "                article.download()\n",
    "                if article.download_state != 2: # controle des liens qui échouent\n",
    "                    print(\"URL non téléchargé: \", link)\n",
    "                    failledlink.append(url)\n",
    "                    continue\n",
    "                article.parse()\n",
    "                df_to_update[link] = {'title' : article.title,\n",
    "                                 'date' : article.publish_date.isoformat(), \n",
    "                                 'author' : article.authors, \n",
    "                                 'category' : category, \n",
    "                                 'content' : article.text, \n",
    "                                 'image_link' : article.top_image}\n",
    "    \n",
    "    # saving\n",
    "    with open(\"data_out/update_lemonde\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".json\", 'w') as jsonfile:\n",
    "        json.dump(df_to_update, jsonfile)\n",
    "    \n",
    "    print(\"Length after updating data: \", len(df_to_update))\n",
    "    print(\"Temps: \",round((t2-t1),1), \"s\")\n",
    "    \n",
    "    \n",
    "    return df_to_update, failledlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_data, failled_links = updatrss(unitstest, update_monde, sleeptime=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction d’information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
